---
knit: (function(inputFile, encoding) {rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../content/labs")})
output:
  html_document:
    css: ../../_HeadersEtc/style.css
    highlight: default
    theme: paper
editor_options: 
  chunk_output_type: console
---

<img src="../../_HeadersEtc/SESYNCBayes/logo_plus_grants.png" style="position:relative;float:right;padding-top:10px;width:150px;height=150px" />

##### `r readChar("../../_HeadersEtc/SESYNCBayes/Title.txt", file.info("../../_HeadersEtc/SESYNCBayes/Title.txt")$size)`

#### Estimating Model Parameters Using Maximum Likelihood 

##### `r format(Sys.Date(), format="%B %d, %Y")`

```{r preliminaries, include = FALSE}
library(knitr)
library(SESYNCBayes)
knitr::opts_chunk$set(cache = FALSE)
set.seed(10)
```

-----

### **General approach**

To get the most out of this lab, you must think of the specific problems you confront here as examples from an infinite variety of analytical challenges that can be attacked using the same general approach:

* Think about how the data arise.
* Develop a mathematical model of the process that produces the data.
* Choose the appropriate likelihood function to tie the predictions of your process model to the data. 
* Use maximum likelihood (in this exercise) or Bayesian methods (later) to learn about the parameters in your process model and associated uncertainties.
* In this exercise we will not attempt to distinguish among different sources of uncertainty, i.e., process variance, observation error, and random effects.  These distinctions will be made soon enough, after we have developed a bit more statistical sophistication.  Moreover, we are leaving the problem of model selection until later in the course.

<br>

---

### **Problem**

Coates and Burton (1999) studied the influence of light availability on growth increment of saplings of species of conifers in northwestern interior cedar-hemlock forests of British Columbia.  They used the deterministic model, 

$$\mu_{i}=\cfrac{\alpha\big(L_{i}-c\big)}{\cfrac{\alpha}{\gamma} + \big(L_{i}-c\big)},$$

where:

$\mu_{i}$ = prediction of growth increment of the $i_{th}$ hemlock tree (cm/year)

$\alpha$ = maximum growth rate (cm/year)

$\gamma$ = slope of curve at low light (cm/year)

$c$ = light index where growth = 0 (unitless)

$L_{i}$ = measured index of light availability for the $i_{th}$ hemlock tree, i.e. the proportion of the hemisphere above canopy open to light $\times$ 100 (unitless).

We will return to this model several times during the course.

1. Assume that growth increment can be any real number.  It can negative because moose can eat the tops of saplings.  Write a model for the data.

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV1"> Answer </button>  
<div id="myDIV1" class="collapse"> 
<br>

$$\mu_{i}=\cfrac{\alpha\big(L_{i}-c\big)}{\cfrac{\alpha}{\gamma} + \big(L_{i}-c\big)}$$
$$y_i \sim \text{normal}(\mu_i,\sigma^2)$$

</div>

<br>

---

### **Getting started**

Obtain maximum likelihood estimates (MLE’s) of the model parameters using Solver in Excel. Ok, ok, you have invested buckets of time and effort learning R and now we are asking you to work in Excel?  What are were thinking?  There is a reason for this.  When you write code in R, it is easy to fail to understand exactly what is happening “under the hood.” The structure of a maximum likelihood analysis is much more transparent when you are forced to build a spreadsheet. You may be delighted to know that this is the last time you will do this in this course.

Open the spreadsheet containing the light limitation data (**HemlockLightLikelihood.xlsx**).  In the next section you will add the proper formulas to columns and cells on the this sheet to demonstrate that you know how likelihood works.  Your spreadsheet will look something like this before answering questions 1 -- 9:

<br>

![ ](../../_Graphics/HemlockLightExampleImage1.png)

<br>

---

### **Setting up the spreadsheet**

Let’s think about the columns and the rows.  This is the benefit of this exercise, so please linger on this, discussing the layout of this spreadsheet with your classmates and calling on the instructors if you don’t understand it. 

* Columns A and B should be easy, these are the data. 

* Column C contains the prediction of your model for each level of light. These predictions depend on the values for $\alpha$, $\gamma$, and $c$ contained in column I.

* Column D contain the squared difference between observations and predictions.

* Column E contains the the probability density of the data conditional on $\mu_{i}$ and $\sigma$, one value for each data point. The excel formula for this quantity is `=NORMDIST(B2,C2,I$5,FALSE)` for the first observation, with the numeric counter for B and C incrementing with each row.

* Cells I2 -- I4 contain the values for $\alpha$, $\gamma$, and $c$ that are used to form the predicted growth rate as a function of light level (column C). Cell I5 contains the value for $\sigma$. Right now these cells are set to either 1 or 2. **You will replace these with better initial values before using the solver to find the maximum likelihood estimates (MLE) for each of these parameters.**

* Make a scatterplot of the data and the model predictions, where the x-axis is light level and the y-axis is growth increment. Plot the observed growth increments in blue and the predicted growth increments in green. For the moment, the predicted growth increments should form a line of points along the x-axis. 

<br>

Answer the following questions before proceeding.

1. How could you use the data to help you find good initial conditions for model parameters? 

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV2"> Answer </button>  
<div id="myDIV2" class="collapse"> 
<br>

Fitting model predictions by eye is a useful way to find reasonable initial values. You can get reasonable guesses for $c$ and $\alpha$ by simply looking at the plot of the data.

</div>

<br>

2. Adjust the values for $\alpha$, $\gamma$, and $c$ until you get predictions that look reasonable in your plot.  How could we get a better initial value for $\sigma$?

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV3"> Answer </button>  
<div id="myDIV3" class="collapse"> 
<br>

By calculating the standard deviation as:

$$\sqrt{\sum_1^n\frac{1}{n}(y_i-\mu_i)^2}$$.

</div>

<br>

3. Write the mathematics (the full equation) that is implemented in the formula in column E.

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV4"> Answer </button>  
<div id="myDIV4" class="collapse"> 
<br>

$$
L\big(\,\mu_{i},\sigma \mid y_{i}\,\big) = \cfrac{1}{\sigma\sqrt{2\pi}}e^{-\cfrac{\big(y_{i}-\mu_{i}\big)^{2}}{2\sigma^{2}}}\\[3em]
$$
</div>

<br>

4. Describe the correspondence between $y_{i}$, $\mu_{i}$, and $\sigma$ from the equation you wrote for the previous question and the columns and cells in your spreadsheet.  

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV5"> Answer </button>  
<div id="myDIV5" class="collapse"> 
<br>

The y<sub>i</sub> are the cells in column B, $\mu_{i}$ are the predictions of the model for each light level in column C, and $\sigma$ is one of the parameters to be estimated in cell I5.

</div>

<br>

5. What is the reason for the argument “FALSE” in the Excel formula in column E?

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV6"> Answer </button>  
<div id="myDIV6" class="collapse"> 
<br>

It toggles the function from the CDF when the argument is "TRUE" to the PDF when it is false.

</div>

<br>

6. What does the function return when that argument is “TRUE”? 

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV7"> Answer </button>  
<div id="myDIV7" class="collapse"> 
<br>

See answer to 5.

</div>

<br>

7. In column F we take the logs of the likelihoods, which are summed in cell K2.  If we had not taken the logs and instead, worked directly with the likelihoods, what formula would we use in K2?

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV8"> Answer </button>  
<div id="myDIV8" class="collapse"> 
<br>

The product.

</div>

<br>

8. What are some potential computational problems with using the individual likelihoods rather than the log likelihoods to estimate the total likelihood? 

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV9"> Answer </button>  
<div id="myDIV9" class="collapse"> 
<br>

Underflow.

</div>

<br>

9. This model violates a fundamental assumption of traditional regression analysis.  What is that assumption?  How might you fix the problem? (Hint: think about what we are assuming about the covariate, light availability.)

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV10"> Answer </button>  
<div id="myDIV10" class="collapse"> 
<br>

We are assuming that the predictor variables are measured without error. However, what we are actually interested in is the light seen by the tree.  The x-values are an imperfect approximation of this unobserved quantity.

</div>

<br>

---

### **Using Solver**

Use Solver to find the maximum likelihood estimates of the parameters using the spreadsheet you have constructed.  Solver is a sophisticated non-linear numerical optimizer that uses Newton's method to find values of parameters of a function that maximize or minimize the output of the function.  

If you have never used Solver, the main dialog box looks something like this:
    
<br>

<div style="width:400px; height=300px; margin:0 auto;">
![](../../_Graphics/HemlockLightExampleImage2.png)
</div>

<br>

Put the cell containing the sum of the log likelihoods in the **Set Objective** field.  The cells containing the parameter values will go into the **By Changing Variable Cells** field.  Most likely, you will be able to do the exercises without putting constraints on the parameter values if you give them reasonable starting values.  However, constraining parameters to reasonable values (e.g., $\alpha$ must be positive and can’t be too large) will prevent numerical errors and speed execution time.

10. How might you use the squared error column D to compute $\sigma$? Make this computation and compare with your maximum likelihood estimate of $\sigma$ obtained using Solver.

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV11"> Answer </button>  
<div id="myDIV11" class="collapse"> 
<br>

You could use the squared error column D to compute sigma just as you did above for question 2. In this case, they should be very similar to one another as these are really measuring the same quantity of interest, where one is an empirical realization of the other, which is a parameter.

</div>


<br>

---

### **Using R to do the same thing**

Check your results using the `nls` function in R, which does non-linear estimation for normally distributed data. Examine the assumption that the model residuals are normally distributed using `qqnorm`.  To speed things along, we have given you the syntax, but for it to be useful to you, you must study it and experiment a bit.  In particular, you must do a help on `nls` and look at its `methods—summary`, `predict`, `coef`, and `residuals`. The hemlock light and growth increment data are included in the `SESYNCBayes` library as `HemlockLight`.

```{r, eval = TRUE, fig.align = 'center'}
plot(HemlockLight$L, HemlockLight$g_rate, ylab = "Growth rate (cm/yr)", xlab = ("Light Availability"))
x = HemlockLight$L
y = HemlockLight$g_rate
model = nls(y ~ a * (x - c)/(a/s + x - c), trace = TRUE, start = c(a = 50, s = 2, c = 8))
summary(model)
p = (coef(model))
a.hat = p[1]
s.hat = p[2]
c.hat = p[3]
yhat = predict(model)
lines(x, yhat, col = "red")
```

<br>

---

### **ADVANCED: Incorporating prior information in an MLE**

Suppose that a previous study reported a mean value of $\alpha$ = 35 with a standard deviation of the mean =  4.25.You may use a normal distribution to represent the prior information on $\alpha$. Write  a model for the data that includes the prior information.

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV11A"> Answer </button>  
<div id="myDIV11A" class="collapse"> 
<br>

$$L(\alpha, \gamma, c,\sigma \mid \mathbf{y}) =\prod_{i=1}^n\big(\text{normal}(g(\alpha,\gamma,c,L_i),\sigma^2)\big)\text{normal}(\alpha \mid 35,4.25)$$

</div>

<br>

Incorporate these prior data in your MLE estimate of $\alpha$. Hint: create a likelihood function for the probability of the new value of $\alpha$ conditional on the previous value and its standard deviation. How do you combine likelihoods (or log likelihoods) to obtain a total likelihood? Do this in Excel.

11. Describe what happens to the estimate of α relative to the one you obtained earlier. What is going on? 

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV12"> Answer </button>  
<div id="myDIV12" class="collapse"> 
<br>

The estimate of alpha represents a compromise between the estimate based on the data and the prior distribution of alpha.

</div>

<br>

12. What is the effect of increasing the prior standard deviation on the new estimate? What happens when it shrinks?

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV13"> Answer </button>  
<div id="myDIV13" class="collapse"> 
<br>

The effect of the prior distribution of alpha depends on its standard deviation.  Small values cause the current estimate of alpha to more closely resemble the prior mean.

</div>

<br>

13.  There is a single log likelihood for the prior distribution but the sum of many for the data. This seems "unfair."  Explain how the prior distribtion can overwhelm the data and vice versa.

<button class="btn btn-primary" data-toggle="collapse" data-target="#myDIV14"> Answer </button>  
<div id="myDIV14" class="collapse"> 
<br>

The prior distribution might have been based on thousands of data points.  The prior distribution can overwhelm the data when it has a very small variance relative to the variance in the likelihood profile for alpha. The data can overwhelm the prior when the likelihood profile of $\alpha$ has a much lower variance than the variance of the prior. 

</div>

<br>

---

### **References**

Coates, K.D., Burton P.J., 1999. Growth of planted tree seedlings in response to ambient light levels in northwestern interior cedar-hemlock forests of British Columbia. *Canadian Journal of Forest Research*, 1999, 29(9): 1374-1382, [10.1139/x99-091](http://northernforestatlas.com/research/pubs/burton_coates_1999_can_j_for_res.pdf)

